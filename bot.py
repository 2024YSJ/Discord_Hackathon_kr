import os
import requests
import json
from datetime import datetime
from bs4 import BeautifulSoup
import time
import re
# ì„¤ì •
WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')
DB_FILE = "sent_hackathons.txt"

class HackathonBot:
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        # Kaggle ì „ìš© í—¤ë” (base_headers ëŒ€ìš©)
        self.base_headers = self.headers.copy()
        self.sent_list = self.load_sent_list()

    def load_sent_list(self):
        if os.path.exists(DB_FILE):
            with open(DB_FILE, "r", encoding="utf-8") as f:
                return set(line.strip() for line in f if line.strip())
        return set()

    def save_sent_list(self, new_items):
        with open(DB_FILE, "a", encoding="utf-8") as f:
            for item in new_items:
                f.write(f"{item['title']}\n")

    # --- í”Œë«í¼ë³„ í¬ë¡¤ëŸ¬/API í˜¸ì¶œ ë©”ì„œë“œ (í´ë˜ìŠ¤ ë‚´ë¶€ë¡œ ë“¤ì—¬ì“°ê¸° ì™„ë£Œ) ---

    def fetch_devpost(self):
        try:
            custom_headers = self.headers.copy()
            custom_headers.update({
                "Accept": "application/json, text/javascript, */*; q=0.01",
                "Referer": "https://devpost.com/hackathons",
                "X-Requested-With": "XMLHttpRequest"
            })
            params = {"status[]": "upcoming", "sort_by": "Recently Added"}
            url = "https://devpost.com/api/hackathons"
            res = requests.get(url, params=params, headers=custom_headers, timeout=15)
            if res.status_code == 200:
                data = res.json()
                hackathons = data.get('hackathons', [])
                return [{"title": h['title'], "url": h['url'], "host": "Devpost", "date": h.get('submission_period_dates', 'N/A')} for h in hackathons]
            return []
        except: return []

    def fetch_mlh(self):
        try:
            # íŠ¹ì • ì—°ë„ í•„í„° ì—†ì´ ì „ì²´ë¥¼ ê°€ì ¸ì™€ì„œ ë¡œì»¬ì—ì„œ í•„í„°ë§í•˜ëŠ” ê²ƒì´ ëˆ„ë½ì„ ë°©ì§€í•¨
            res = requests.get("https://mlh.io/api/v1/hackathons", headers=self.headers, timeout=15)
            if res.status_code == 200:
                now = datetime.now().strftime('%Y-%m-%d')
                return [{"title": h['name'], "url": h['url'], "host": "MLH", "date": h['start_date']} 
                        for h in res.json() if h.get('start_date', '') >= now]
        except: pass
        return []

    def fetch_devfolio(self):
        try:
            dev_headers = self.headers.copy()
            dev_headers.update({"Origin": "https://devfolio.co", "Referer": "https://devfolio.co/hackathons", "X-Requested-With": "XMLHttpRequest"})
            url = "https://api.devfolio.co/api/hackathons"
            res = requests.post(url, json={"type": "open", "limit": 15, "range": "upcoming"}, headers=dev_headers, timeout=15)
            if res.status_code == 200:
                return [{"title": h.get('name'), "url": f"https://{h.get('slug')}.devfolio.co", "host": "Devfolio", "date": h.get('start_date', 'N/A')} for h in res.json().get('result', []) if h.get('slug')]
            return []
        except: return []

    def fetch_dorahacks(self):
            try:
                # í•´ì»¤í†¤ ëª©ë¡ í˜ì´ì§€ ì§ì ‘ íƒ€ê²©
                url = "https://dorahacks.io/hackathon"
                res = requests.get(url, headers=self.headers, timeout=15)
                soup = BeautifulSoup(res.text, 'html.parser')
                script = soup.find('script', id='__NEXT_DATA__')
                if script:
                    data = json.loads(script.string)
                    # Next.jsì˜ ë³µì¡í•œ ë°ì´í„° íŠ¸ë¦¬ êµ¬ì¡° ì •ë°€ íƒìƒ‰
                    queries = data.get('props', {}).get('pageProps', {}).get('apolloState', {})
                    results = []
                    for key, value in queries.items():
                        if key.startswith('Hackathon:') and value.get('name'):
                            results.append({
                                "title": value['name'],
                                "url": f"https://dorahacks.io/hackathon/{value.get('id')}",
                                "host": "DoraHacks",
                                "date": "ìƒì„¸ í™•ì¸"
                            })
                    return results
            except: pass
            return []

    def fetch_unstop(self):
        try:
            url = "https://unstop.com/api/public/opportunity/search-result?opportunity=hackathons&per_page=15"
            res = requests.get(url, headers=self.headers, timeout=15)
            if res.status_code == 200:
                items = res.json().get('data', {}).get('data', [])
                return [{"title": h.get('title'), "url": f"https://unstop.com/p/{h.get('public_url')}", "host": "Unstop", "date": h.get('reg_end_date', 'N/A').split('T')[0]} for h in items if h.get('public_url')]
            return []
        except: return []

    def fetch_kaggle(self):
        try:
            url = "https://www.kaggle.com/competitions?hostSegmentIdFilter=8"
            res = requests.get(url, headers=self.headers, timeout=15)
            # JSON ë°ì´í„°ë¥¼ ë½‘ì•„ë‚´ê¸° ìœ„í•œ ë” ì •ë°€í•œ ì •ê·œí‘œí˜„ì‹
            match = re.search(r'window\.Kaggle\.State\s*=\s*({.*?});(?=\s*window|$)', res.text, re.DOTALL)
            if match:
                data = json.loads(match.group(1))
                items = data.get('competitionListing', {}).get('competitions', [])
                return [{"title": i['title'], "url": f"https://www.kaggle.com/c/{i['ref']}", "host": "Kaggle", "date": i.get('deadline')} for i in items]
        except: pass
        return []

    def fetch_hack2skill(self):
        try:
            url = "https://api.hack2skill.com/gethackathons"
            res = requests.get(url, headers=self.headers, timeout=15)
            if res.status_code == 200:
                return [{"title": h.get('name'), "url": f"https://hack2skill.com/hackathon/{h.get('slug')}", "host": "Hack2Skill", "date": h.get('start_date', 'N/A').split('T')[0]} for h in res.json().get('data', []) if h.get('slug')]
            return []
        except: return []

    def fetch_programmers(self):
        try:
            # íŠ¹ì • ì¹´í…Œê³ ë¦¬ê°€ ì•„ë‹Œ ì „ì²´ ì±Œë¦°ì§€ í˜ì´ì§€
            url = "https://programmers.co.kr/learn/challenges"
            res = requests.get(url, headers=self.headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            results = []
            # 'challenge-card' í´ë˜ìŠ¤ ì™¸ì— ì œëª©ì„ í¬í•¨í•˜ëŠ” ëª¨ë“  ë§í¬ íƒìƒ‰
            for a in soup.select('a[href*="/learn/challenges/"]'):
                title_el = a.select_one('h4, .title, h5')
                if title_el:
                    title = title_el.get_text(strip=True)
                    if any(k in title for k in ['í•´ì»¤í†¤', 'ì±Œë¦°ì§€', 'ëŒ€íšŒ']):
                        results.append({
                            "title": f"ğŸ‡°ğŸ‡· [í”„ë¡œê·¸ë˜ë¨¸ìŠ¤] {title}",
                            "url": "https://programmers.co.kr" + a['href'],
                            "host": "Programmers", "date": "ìƒì„¸ í™•ì¸"
                        })
            return results
        except: pass
        return []

    def fetch_devevent(self):
        try:
            # ì›¹í˜ì´ì§€ ëŒ€ì‹  ê°œë°œìê°€ ê´€ë¦¬í•˜ëŠ” GitHubì˜ Raw JSONì„ ì§ì ‘ íƒ€ê²© (ì°¨ë‹¨ 0%)
            url = "https://raw.githubusercontent.com/one-meter/dev-event/master/lib/events.json"
            res = requests.get(url, timeout=15)
            if res.status_code == 200:
                now = datetime.now().strftime('%Y-%m-%d')
                return [{"title": f"ğŸ‡°ğŸ‡· [ë°ë¸Œì´ë²¤íŠ¸] {e['title']}", "url": e['link'], "host": "DevEvent", "date": e['startDate']} 
                        for e in res.json() if ('í•´ì»¤í†¤' in e['title'] or 'Hackathon' in e['title']) and e.get('endDate', '9999-12-31') >= now]
        except: pass
        return []

    def fetch_goorm(self):
        try:
            # êµ¬ë¦„ì€ ìµœê·¼ 'ì—ë“€'ì™€ 'ë ˆë²¨' ì„¹ì…˜ì´ í†µí•©ë˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤.
            url = "https://level.goorm.io/l/challenge"
            res = requests.get(url, headers=self.headers, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            results = []
            # ì¹´ë“œ ë ˆì´ì•„ì›ƒì˜ ê³µí†µ ë¶€ëª¨ íƒìƒ‰
            for item in soup.find_all(['div', 'a'], class_=re.compile(r'card|item|challenge')):
                title_el = item.find(['h3', 'h4', 'div'], class_=re.compile(r'title|name'))
                if title_el:
                    title = title_el.get_text(strip=True)
                    link_el = item if item.name == 'a' else item.find('a')
                    if link_el and link_el.get('href'):
                        results.append({
                            "title": f"ğŸ‡°ğŸ‡· [êµ¬ë¦„] {title}",
                            "url": "https://level.goorm.io" + link_el['href'],
                            "host": "goorm", "date": "ìƒì„¸ í™•ì¸"
                        })
            return results
        except: pass
        return []

    def run(self):
        print("ğŸ” í•´ì»¤í†¤ ì •ë³´ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        all_hackathons = []
        
        # í•¨ìˆ˜ ëª©ë¡ê³¼ ì´ë¦„ ë§¤í•‘
        tasks = [
            ("Devpost", self.fetch_devpost),
            ("MLH", self.fetch_mlh),
            ("Devfolio", self.fetch_devfolio),
            ("Unstop", self.fetch_unstop),
            ("Kaggle", self.fetch_kaggle),
            ("Hack2Skill", self.fetch_hack2skill),
            ("DoraHacks", self.fetch_dorahacks),
            ("Programmers", self.fetch_programmers),
            ("DevEvent", self.fetch_devevent),
            ("goorm", self.fetch_goorm)
        ]
        
        for name, fetcher in tasks:
            try:
                found = fetcher()
                print(f"ğŸ“¡ {name}: {len(found)}ê°œ ë°œê²¬") # ë¡œê·¸ ì¶œë ¥
                all_hackathons.extend(found)
            except Exception as e:
                print(f"âŒ {name} ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

        # ì¤‘ë³µ ì œê±°
        new_items = [h for h in all_hackathons if h['title'] not in self.sent_list]
        print(f"ğŸ“Š ìµœì¢… ì‹ ê·œ ê³µê³ : {len(new_items)}ê°œ")

        if not new_items:
            return

        self.send_to_discord(new_items)
        self.save_sent_list(new_items)

    def send_to_discord(self, hackathons):
        for i in range(0, len(hackathons), 10):
            chunk = hackathons[i:i+10]
            embeds = []
            for h in chunk:
                embeds.append({
                    "title": f"ğŸ† {h['title']}",
                    "url": h['url'],
                    "color": 3447003,
                    "fields": [
                        {"name": "í”Œë«í¼", "value": h['host'], "inline": True},
                        {"name": "ë§ˆê°/ì¼ì •", "value": str(h['date']), "inline": True}
                    ]
                })
            payload = {
                "content": "ğŸš€ **ìƒˆë¡œìš´ í•´ì»¤í†¤ ëŒ€íšŒê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤!**" if i == 0 else "",
                "embeds": embeds
            }
            requests.post(WEBHOOK_URL, json=payload)

if __name__ == "__main__":
    if not WEBHOOK_URL:
        print("âŒ ì˜¤ë¥˜: DISCORD_WEBHOOK_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        bot = HackathonBot()
        bot.run()
